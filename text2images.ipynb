{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "caba5134",
   "metadata": {},
   "source": [
    "# Generate image dataset for Khmer text recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "73057e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "from PIL import features\n",
    "print(features.check(\"raqm\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0373e6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil\n",
    "from IPython.display import FileLink"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33eb10e0",
   "metadata": {},
   "source": [
    "## 1. Load datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42d2d71",
   "metadata": {},
   "source": [
    "### 1.1 Loading text word "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "699d0e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Loaded 2190188 words from combined_cleaned.txt\n",
      "Sample words: ['អាណិត', 'គាត', 'ណាស់', 'លោក', '៨០']\n",
      "\n",
      "DataFrame shape: (2190188, 1)\n"
     ]
    }
   ],
   "source": [
    "# 1.1. Loading words data\n",
    "dataset_path = 'combined_cleaned.txt'\n",
    "\n",
    "# Read all words from the text file\n",
    "with open(dataset_path, 'r', encoding='utf-8') as f:\n",
    "    words = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "print(f\"\\n✓ Loaded {len(words)} words from {dataset_path}\")\n",
    "print(f\"Sample words: {words[:5]}\")\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame({'word': words})\n",
    "print(f\"\\nDataFrame shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e3b3e1",
   "metadata": {},
   "source": [
    "## 2: Generate text to images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58798cc9",
   "metadata": {},
   "source": [
    "### 2.1. Import function for generate text to image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ef752ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_khmer_text_image(index, content, data_type, bg, \n",
    "                        font_path, font_size, data_folder, padding=10):\n",
    "    \"\"\"\n",
    "    Generate an image from Khmer text with specified styling parameters\n",
    "    Image size adapts to text content\n",
    "    \n",
    "    Args:\n",
    "        index: Index number for filename\n",
    "        content: The text to render\n",
    "        data_type: 'train', 'valid', or 'test'\n",
    "        bg: Background color (R, G, B, A)\n",
    "        font_path: Path to the font file\n",
    "        font_size: Size of the font\n",
    "        data_folder: Base folder for output\n",
    "        padding: Padding around text (pixels)\n",
    "    \n",
    "    Returns:\n",
    "        Filename of the generated image\n",
    "    \"\"\"\n",
    "    # Load font first to measure text\n",
    "    try:\n",
    "        font = ImageFont.truetype(font_path, font_size)\n",
    "    except:\n",
    "        print(f\"Warning: Could not load font {font_path}, using default\")\n",
    "        font = ImageFont.load_default()\n",
    "    \n",
    "    # Create temporary image to measure text\n",
    "    temp_img = Image.new('RGBA', (1, 1))\n",
    "    temp_draw = ImageDraw.Draw(temp_img)\n",
    "    \n",
    "    # Get text bounding box\n",
    "    bbox = temp_draw.textbbox((0, 0), content, font=font)\n",
    "    text_width = bbox[2] - bbox[0]\n",
    "    text_height = bbox[3] - bbox[1]\n",
    "    \n",
    "    # Calculate image size based on text with padding\n",
    "    img_width = text_width + (padding * 2)\n",
    "    img_height = text_height + (padding * 2)\n",
    "    \n",
    "    # Create actual image with calculated size\n",
    "    image = Image.new('RGBA', (img_width, img_height), bg)\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    \n",
    "    # Draw text with padding offset\n",
    "    draw.text((padding, padding), content, font=font, fill=(0, 0, 0, 255))\n",
    "    \n",
    "    # Generate filename with 6-digit index\n",
    "    filename = f\"{index:06d}.png\"\n",
    "    \n",
    "    # Create output directory if it doesn't exist\n",
    "    output_dir = os.path.join(data_folder, data_type)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Save image\n",
    "    output_path = os.path.join(output_dir, filename)\n",
    "    image.save(output_path)\n",
    "    \n",
    "    return filename\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbfaf1b",
   "metadata": {},
   "source": [
    "### 2.2. Define Variant values for Function Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "846a9213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Discovered fonts:\n",
      "  • fonts\\KhmerDigital-Black.ttf\n",
      "  • fonts\\KhmerDigital-Bold.ttf\n",
      "  • fonts\\KhmerDigital-ExtraBold.ttf\n",
      "  • fonts\\KhmerDigital-ExtraLight.ttf\n",
      "  • fonts\\KhmerDigital-Light.ttf\n",
      "  • fonts\\KhmerDigital-Medium.ttf\n",
      "  • fonts\\KhmerDigital-Regular.ttf\n",
      "  • fonts\\KhmerDigital-SemiBold.ttf\n",
      "  • fonts\\KhmerDigital-Thin.ttf\n",
      "  • fonts\\KhmerDigitalMax.ttf\n",
      "  • fonts\\KhmerDigitalNumber.ttf\n",
      "  • fonts\\KhmerDigitalNumberMax.ttf\n",
      "  • fonts\\KhmerMPTC.ttf\n",
      "  • fonts\\KhmerMPTCMoul.otf\n",
      "  • fonts\\KhmerOS_muollight.ttf\n",
      "  • fonts\\KhmerOS_siemreap.ttf\n",
      "\n",
      "✓ 16 fonts\n",
      "✓ 8 font sizes\n",
      "✓ 1 background colors\n"
     ]
    }
   ],
   "source": [
    "fonts_dir = \"fonts\"\n",
    "fonts = []\n",
    "\n",
    "if os.path.exists(fonts_dir):\n",
    "    for filename in os.listdir(fonts_dir):\n",
    "        if filename.endswith(('.ttf', '.otf', '.TTF', '.OTF')):\n",
    "            font_path = os.path.join(fonts_dir, filename)\n",
    "            fonts.append(font_path)\n",
    "    fonts.sort()  # Sort alphabetically for consistency\n",
    "else:\n",
    "    print(f\"Warning: '{fonts_dir}' folder not found!\")\n",
    "    fonts = []\n",
    "\n",
    "if not fonts:\n",
    "    print(\"ERROR: No font files found in 'fonts/' folder!\")\n",
    "    print(\"Please ensure .ttf or .otf font files are in the 'fonts/' directory\")\n",
    "    exit()\n",
    "\n",
    "print(f\"\\nDiscovered fonts:\")\n",
    "for font in fonts:\n",
    "    print(f\"  • {font}\")\n",
    "\n",
    "# Font sizes\n",
    "font_sizes = [9,10,11,12,13,14,15,16]\n",
    "\n",
    "# Background colors\n",
    "bg_colors = [\n",
    "    (255, 255, 255, 255),\n",
    "]\n",
    "\n",
    "print(f\"\\n✓ {len(fonts)} fonts\")\n",
    "print(f\"✓ {len(font_sizes)} font sizes\")\n",
    "print(f\"✓ {len(bg_colors)} background colors\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b5a6b5",
   "metadata": {},
   "source": [
    "### 2.3 Splitting The Dataset: Train, Validation, Test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1df9f4bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2.3. Splitting the dataset...\n",
      "✓ Train: 1533131 words\n",
      "✓ Validation: 328528 words\n",
      "✓ Test: 328529 words\n"
     ]
    }
   ],
   "source": [
    "# 2.3 Splitting The Dataset: Train, Validation, Test\n",
    "print(\"\\n2.3. Splitting the dataset...\")\n",
    "\n",
    "# Split: 70% train, 15% validation, 15% test\n",
    "train, temp = train_test_split(df, test_size=0.3, random_state=42)\n",
    "valid, test = train_test_split(temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Reset indices for proper numbering\n",
    "train = train.reset_index(drop=True)\n",
    "valid = valid.reset_index(drop=True)\n",
    "test = test.reset_index(drop=True)\n",
    "\n",
    "print(f\"✓ Train: {len(train)} words\")\n",
    "print(f\"✓ Validation: {len(valid)} words\")\n",
    "print(f\"✓ Test: {len(test)} words\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2942534d",
   "metadata": {},
   "source": [
    "### 2.4 Generating Text to Images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ebf17d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.4 Generating Text to Images\n",
    "# Create base output directory\n",
    "data_folder = \"data_v1\"\n",
    "os.makedirs(data_folder, exist_ok=True)\n",
    "\n",
    "# Lists to store labels\n",
    "train_labels = []\n",
    "valid_labels = []\n",
    "test_labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b3142f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------------------------------\n",
      "Generating TRAIN images...\n",
      "------------------------------------------------------------\n",
      "100 of 1533131: complete\n",
      "200 of 1533131: complete\n",
      "300 of 1533131: complete\n",
      "400 of 1533131: complete\n",
      "500 of 1533131: complete\n",
      "600 of 1533131: complete\n",
      "700 of 1533131: complete\n",
      "800 of 1533131: complete\n",
      "900 of 1533131: complete\n",
      "1000 of 1533131: complete\n",
      "1100 of 1533131: complete\n",
      "1200 of 1533131: complete\n",
      "1300 of 1533131: complete\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileExistsError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen os>:225\u001b[39m, in \u001b[36mmakedirs\u001b[39m\u001b[34m(name, mode, exist_ok)\u001b[39m\n",
      "\u001b[31mFileExistsError\u001b[39m: [WinError 183] Cannot create a file when that file already exists: 'data_v1\\\\train'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     12\u001b[39m bg = random.choice(bg_colors)\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m     filename = \u001b[43mgen_khmer_text_image\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m+\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mword\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdata_type\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtrain\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbg\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfont_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfont\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfont_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfont_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdata_folder\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_folder\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m     train_labels.append(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mrow[\u001b[33m'\u001b[39m\u001b[33mword\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 52\u001b[39m, in \u001b[36mgen_khmer_text_image\u001b[39m\u001b[34m(index, content, data_type, bg, font_path, font_size, data_folder, padding)\u001b[39m\n\u001b[32m     50\u001b[39m \u001b[38;5;66;03m# Create output directory if it doesn't exist\u001b[39;00m\n\u001b[32m     51\u001b[39m output_dir = os.path.join(data_folder, data_type)\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmakedirs\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[38;5;66;03m# Save image\u001b[39;00m\n\u001b[32m     55\u001b[39m output_path = os.path.join(output_dir, filename)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen os>:229\u001b[39m, in \u001b[36mmakedirs\u001b[39m\u001b[34m(name, mode, exist_ok)\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# Generating training data to image\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"-\"*60)\n",
    "print(\"Generating TRAIN images...\")\n",
    "print(\"-\"*60)\n",
    "i = 1\n",
    "n = len(train)\n",
    "for index, row in train.iterrows():\n",
    "    font_size = random.choice(font_sizes)\n",
    "    font = random.choice(fonts)\n",
    "    bg = random.choice(bg_colors)\n",
    "    \n",
    "    try:\n",
    "        filename = gen_khmer_text_image(\n",
    "            index=index+1, \n",
    "            content=row[\"word\"],\n",
    "            data_type=\"train\", \n",
    "            bg=bg,\n",
    "            font_path=font, \n",
    "            font_size=font_size,\n",
    "            data_folder=data_folder\n",
    "        )\n",
    "        \n",
    "        train_labels.append(f\"{filename}\\t{row['word']}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing word '{row['word']}': {e}\")\n",
    "        continue\n",
    "    \n",
    "    if i % 100 == 0 or i == n:\n",
    "        print(f\"{i} of {n}: complete\")\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ddca1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Generating validation data to image\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"-\"*60)\n",
    "print(\"Generating VALID images...\")\n",
    "print(\"-\"*60)\n",
    "i = 1\n",
    "n = len(valid)\n",
    "for index, row in valid.iterrows():\n",
    "    font_size = random.choice(font_sizes)\n",
    "    font = random.choice(fonts)\n",
    "    bg = random.choice(bg_colors)\n",
    "    \n",
    "    try:\n",
    "        filename = gen_khmer_text_image(\n",
    "            index=index+1, \n",
    "            content=row[\"word\"],\n",
    "            data_type=\"valid\", \n",
    "            bg=bg,\n",
    "            font_path=font, \n",
    "            font_size=font_size,\n",
    "            data_folder=data_folder\n",
    "        )\n",
    "        \n",
    "        valid_labels.append(f\"{filename}\\t{row['word']}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing word '{row['word']}': {e}\")\n",
    "        continue\n",
    "    \n",
    "    if i % 100 == 0 or i == n:\n",
    "        print(f\"{i} of {n}: complete\")\n",
    "    i = i + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf5d2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# Generating testing data to image\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"-\"*60)\n",
    "print(\"Generating TEST images...\")\n",
    "print(\"-\"*60)\n",
    "i = 1\n",
    "n = len(test)\n",
    "for index, row in test.iterrows():\n",
    "    font_size = random.choice(font_sizes)\n",
    "    font = random.choice(fonts)\n",
    "    bg = random.choice(bg_colors)\n",
    "    \n",
    "    try:\n",
    "        filename = gen_khmer_text_image(\n",
    "            index=index+1, \n",
    "            content=row[\"word\"],\n",
    "            data_type=\"test\", \n",
    "            bg=bg,\n",
    "            font_path=font, \n",
    "            font_size=font_size,\n",
    "            data_folder=data_folder\n",
    "        )\n",
    "        \n",
    "        test_labels.append(f\"{filename}\\t{row['word']}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing word '{row['word']}': {e}\")\n",
    "        continue\n",
    "    \n",
    "    if i % 100 == 0 or i == n:\n",
    "        print(f\"{i} of {n}: complete\")\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6da38c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------------------------------\n",
      "Saving label files...\n",
      "------------------------------------------------------------\n",
      "✓ Saved train.txt (7475 entries)\n",
      "✓ Saved valid.txt (0 entries)\n",
      "✓ Saved test.txt (0 entries)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"-\"*60)\n",
    "print(\"Saving label files...\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "# Save train.txt\n",
    "with open(os.path.join(data_folder, 'train.txt'), 'w', encoding='utf-8') as f:\n",
    "    f.write('\\n'.join(train_labels))\n",
    "print(f\"✓ Saved train.txt ({len(train_labels)} entries)\")\n",
    "\n",
    "# Save valid.txt\n",
    "with open(os.path.join(data_folder, 'valid.txt'), 'w', encoding='utf-8') as f:\n",
    "    f.write('\\n'.join(valid_labels))\n",
    "print(f\"✓ Saved valid.txt ({len(valid_labels)} entries)\")\n",
    "\n",
    "# Save test.txt\n",
    "with open(os.path.join(data_folder, 'test.txt'), 'w', encoding='utf-8') as f:\n",
    "    f.write('\\n'.join(test_labels))\n",
    "print(f\"✓ Saved test.txt ({len(test_labels)} entries)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3564de26",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"GENERATION COMPLETE!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Train images: {len(train_labels)} → data_v1/train/\")\n",
    "print(f\"Valid images: {len(valid_labels)} → data_v1/valid/\")\n",
    "print(f\"Test images: {len(test_labels)} → data_v1/test/\")\n",
    "print(f\"\\nLabel files:\")\n",
    "print(f\"  • data_v1/train.txt\")\n",
    "print(f\"  • data_v1/valid.txt\")\n",
    "print(f\"  • data_v1/test.txt\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7117d47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_filename = \"data_v1\"\n",
    "shutil.make_archive(zip_filename, 'zip', data_folder)\n",
    "\n",
    "print(f\"✓ Created {zip_filename}.zip\")\n",
    "print(f\"✓ File size: {os.path.getsize(zip_filename + '.zip') / (1024*1024):.2f} MB\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DOWNLOAD READY!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Download file: {zip_filename}.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b6ae79",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    display(FileLink(f\"{zip_filename}.zip\"))\n",
    "    print(\"\\nClick the link above to download\")\n",
    "except:\n",
    "    print(f\"\\nTo download, locate the file: {zip_filename}.zip\")\n",
    "    print(\"In Jupyter: Right-click the file in the file browser and select 'Download'\")\n",
    "    print(\"In Colab: Find the file in the Files panel on the left and click the download icon\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
