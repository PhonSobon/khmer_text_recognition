{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fc3ec33",
   "metadata": {},
   "source": [
    "# Train model Khmer Text Recognition (Use model : microsoft/trocr-base-printed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d72abf5",
   "metadata": {},
   "source": [
    "## Step 1. Generate image dataset for Khmer text recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe69abc",
   "metadata": {},
   "source": [
    "### 1. Import library for generate image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10e44d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil\n",
    "from IPython.display import FileLink"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9eaedd9",
   "metadata": {},
   "source": [
    "### 2. Load datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a249d4d2",
   "metadata": {},
   "source": [
    "#### 2.1 Loading text word "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945e1a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1. Loading words data\n",
    "dataset_path = 'combined_cleaned.txt'\n",
    "\n",
    "# Read all words from the text file\n",
    "with open(dataset_path, 'r', encoding='utf-8') as f:\n",
    "    words = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "print(f\"\\n✓ Loaded {len(words)} words from {dataset_path}\")\n",
    "print(f\"Sample words: {words[:5]}\")\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame({'word': words})\n",
    "print(f\"\\nDataFrame shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4baddcff",
   "metadata": {},
   "source": [
    "### 3. Generate text to images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd193d41",
   "metadata": {},
   "source": [
    "#### 3.1. Import function for generate text to image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e94195",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_khmer_text_image(index, content, data_type, bg, \n",
    "                        font_path, font_size, data_folder, padding=10):\n",
    "    \"\"\"\n",
    "    Generate an image from Khmer text with specified styling parameters\n",
    "    Image size adapts to text content\n",
    "    \n",
    "    Args:\n",
    "        index: Index number for filename\n",
    "        content: The text to render\n",
    "        data_type: 'train', 'valid', or 'test'\n",
    "        bg: Background color (R, G, B, A)\n",
    "        font_path: Path to the font file\n",
    "        font_size: Size of the font\n",
    "        data_folder: Base folder for output\n",
    "        padding: Padding around text (pixels)\n",
    "    \n",
    "    Returns:\n",
    "        Filename of the generated image\n",
    "    \"\"\"\n",
    "    # Load font first to measure text\n",
    "    try:\n",
    "        font = ImageFont.truetype(font_path, font_size)\n",
    "    except:\n",
    "        print(f\"Warning: Could not load font {font_path}, using default\")\n",
    "        font = ImageFont.load_default()\n",
    "    \n",
    "    # Create temporary image to measure text\n",
    "    temp_img = Image.new('RGBA', (1, 1))\n",
    "    temp_draw = ImageDraw.Draw(temp_img)\n",
    "    \n",
    "    # Get text bounding box\n",
    "    bbox = temp_draw.textbbox((0, 0), content, font=font)\n",
    "    text_width = bbox[2] - bbox[0]\n",
    "    text_height = bbox[3] - bbox[1]\n",
    "    \n",
    "    # Calculate image size based on text with padding\n",
    "    img_width = text_width + (padding * 2)\n",
    "    img_height = text_height + (padding * 2)\n",
    "    \n",
    "    # Create actual image with calculated size\n",
    "    image = Image.new('RGBA', (img_width, img_height), bg)\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    \n",
    "    # Draw text with padding offset\n",
    "    draw.text((padding, padding), content, font=font, fill=(0, 0, 0, 255))\n",
    "    \n",
    "    # Generate filename with 6-digit index\n",
    "    filename = f\"{index:06d}.png\"\n",
    "    \n",
    "    # Create output directory if it doesn't exist\n",
    "    output_dir = os.path.join(data_folder, data_type)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Save image\n",
    "    output_path = os.path.join(output_dir, filename)\n",
    "    image.save(output_path)\n",
    "    \n",
    "    return filename\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1014cd9c",
   "metadata": {},
   "source": [
    "#### 3.2. Define Variant values for Function Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c34d757",
   "metadata": {},
   "outputs": [],
   "source": [
    "fonts_dir = \"fonts\"\n",
    "fonts = []\n",
    "\n",
    "if os.path.exists(fonts_dir):\n",
    "    for filename in os.listdir(fonts_dir):\n",
    "        if filename.endswith(('.ttf', '.otf', '.TTF', '.OTF')):\n",
    "            font_path = os.path.join(fonts_dir, filename)\n",
    "            fonts.append(font_path)\n",
    "    fonts.sort()  # Sort alphabetically for consistency\n",
    "else:\n",
    "    print(f\"Warning: '{fonts_dir}' folder not found!\")\n",
    "    fonts = []\n",
    "\n",
    "if not fonts:\n",
    "    print(\"ERROR: No font files found in 'fonts/' folder!\")\n",
    "    print(\"Please ensure .ttf or .otf font files are in the 'fonts/' directory\")\n",
    "    exit()\n",
    "\n",
    "print(f\"\\nDiscovered fonts:\")\n",
    "for font in fonts:\n",
    "    print(f\"  • {font}\")\n",
    "\n",
    "# Font sizes\n",
    "font_sizes = [9,10,11,12,13,14,15,16]\n",
    "\n",
    "# Background colors\n",
    "bg_colors = [\n",
    "    (255, 255, 255, 255),\n",
    "]\n",
    "\n",
    "print(f\"\\n✓ {len(fonts)} fonts\")\n",
    "print(f\"✓ {len(font_sizes)} font sizes\")\n",
    "print(f\"✓ {len(bg_colors)} background colors\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be78001",
   "metadata": {},
   "source": [
    "#### 3.3 Splitting The Dataset: Train, Validation, Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9697068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.3 Splitting The Dataset: Train, Validation, Test\n",
    "print(\"\\n2.3. Splitting the dataset...\")\n",
    "\n",
    "# Split: 70% train, 15% validation, 15% test\n",
    "train, temp = train_test_split(df, test_size=0.3, random_state=42)\n",
    "valid, test = train_test_split(temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Reset indices for proper numbering\n",
    "train = train.reset_index(drop=True)\n",
    "valid = valid.reset_index(drop=True)\n",
    "test = test.reset_index(drop=True)\n",
    "\n",
    "print(f\"✓ Train: {len(train)} words\")\n",
    "print(f\"✓ Validation: {len(valid)} words\")\n",
    "print(f\"✓ Test: {len(test)} words\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0e2a93",
   "metadata": {},
   "source": [
    "#### 3.4 Generating Text to Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3965eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.4 Generating Text to Images\n",
    "data_folder = \"data_v1\"\n",
    "os.makedirs(data_folder, exist_ok=True)\n",
    "\n",
    "# Lists to store labels\n",
    "train_labels = []\n",
    "valid_labels = []\n",
    "test_labels = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9360a12f",
   "metadata": {},
   "source": [
    "#### 3.5 Generating training data to image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60a7610",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "n = len(train)\n",
    "for index, row in train.iterrows():\n",
    "    font_size = random.choice(font_sizes)\n",
    "    font = random.choice(fonts)\n",
    "    bg = random.choice(bg_colors)\n",
    "    \n",
    "    try:\n",
    "        filename = gen_khmer_text_image(\n",
    "            index=index+1, \n",
    "            content=row[\"word\"],\n",
    "            data_type=\"train\", \n",
    "            bg=bg,\n",
    "            font_path=font, \n",
    "            font_size=font_size,\n",
    "            data_folder=data_folder\n",
    "        )\n",
    "        \n",
    "        train_labels.append(f\"{filename}\\t{row['word']}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing word '{row['word']}': {e}\")\n",
    "        continue\n",
    "    \n",
    "    if i % 100 == 0 or i == n:\n",
    "        print(f\"{i} of {n}: complete\")\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5812e9",
   "metadata": {},
   "source": [
    "#### 3.6 Generating validation data to image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d9f266",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "n = len(valid)\n",
    "for index, row in valid.iterrows():\n",
    "    font_size = random.choice(font_sizes)\n",
    "    font = random.choice(fonts)\n",
    "    bg = random.choice(bg_colors)\n",
    "    \n",
    "    try:\n",
    "        filename = gen_khmer_text_image(\n",
    "            index=index+1, \n",
    "            content=row[\"word\"],\n",
    "            data_type=\"valid\", \n",
    "            bg=bg,\n",
    "            font_path=font, \n",
    "            font_size=font_size,\n",
    "            data_folder=data_folder\n",
    "        )\n",
    "        \n",
    "        valid_labels.append(f\"{filename}\\t{row['word']}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing word '{row['word']}': {e}\")\n",
    "        continue\n",
    "    \n",
    "    if i % 100 == 0 or i == n:\n",
    "        print(f\"{i} of {n}: complete\")\n",
    "    i = i + 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e005949c",
   "metadata": {},
   "source": [
    "#### 3.7 Generating testing data to image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ca7020",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "n = len(test)\n",
    "for index, row in test.iterrows():\n",
    "    font_size = random.choice(font_sizes)\n",
    "    font = random.choice(fonts)\n",
    "    bg = random.choice(bg_colors)\n",
    "    \n",
    "    try:\n",
    "        filename = gen_khmer_text_image(\n",
    "            index=index+1, \n",
    "            content=row[\"word\"],\n",
    "            data_type=\"test\", \n",
    "            bg=bg,\n",
    "            font_path=font, \n",
    "            font_size=font_size,\n",
    "            data_folder=data_folder\n",
    "        )\n",
    "        \n",
    "        test_labels.append(f\"{filename}\\t{row['word']}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing word '{row['word']}': {e}\")\n",
    "        continue\n",
    "    \n",
    "    if i % 100 == 0 or i == n:\n",
    "        print(f\"{i} of {n}: complete\")\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7627087",
   "metadata": {},
   "source": [
    "#### 3.8 Saving label files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02748be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save train.txt\n",
    "with open(os.path.join(data_folder, 'train.txt'), 'w', encoding='utf-8') as f:\n",
    "    f.write('\\n'.join(train_labels))\n",
    "print(f\"✓ Saved train.txt ({len(train_labels)} entries)\")\n",
    "\n",
    "# Save valid.txt\n",
    "with open(os.path.join(data_folder, 'valid.txt'), 'w', encoding='utf-8') as f:\n",
    "    f.write('\\n'.join(valid_labels))\n",
    "print(f\"✓ Saved valid.txt ({len(valid_labels)} entries)\")\n",
    "\n",
    "# Save test.txt\n",
    "with open(os.path.join(data_folder, 'test.txt'), 'w', encoding='utf-8') as f:\n",
    "    f.write('\\n'.join(test_labels))\n",
    "print(f\"✓ Saved test.txt ({len(test_labels)} entries)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5458392e",
   "metadata": {},
   "source": [
    "## Step 2: TrOCR Training for Khmer Text Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f74b91",
   "metadata": {},
   "source": [
    "### 1: Install Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed51973",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q transformers datasets pillow evaluate jiwer accelerate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81eb61d6",
   "metadata": {},
   "source": [
    "### 2: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6d385b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from transformers import (\n",
    "    TrOCRProcessor, \n",
    "    VisionEncoderDecoderModel,\n",
    "    Seq2SeqTrainer,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    default_data_collator\n",
    ")\n",
    "from datasets import load_metric\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24673e8",
   "metadata": {},
   "source": [
    "### 3: Custom Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3835f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KhmerTextRecognitionDataset(Dataset):\n",
    "    \"\"\"Custom dataset for Khmer text recognition\"\"\"\n",
    "    \n",
    "    def __init__(self, label_file, image_dir, processor, max_target_length=128):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            label_file: Path to the label file (train.txt, valid.txt, test.txt)\n",
    "            image_dir: Directory containing the images\n",
    "            processor: TrOCRProcessor instance\n",
    "            max_target_length: Maximum length of target text\n",
    "        \"\"\"\n",
    "        self.image_dir = image_dir\n",
    "        self.processor = processor\n",
    "        self.max_target_length = max_target_length\n",
    "        \n",
    "        # Load labels\n",
    "        self.samples = []\n",
    "        with open(label_file, 'r', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "                if line:\n",
    "                    parts = line.split('\\t')\n",
    "                    if len(parts) == 2:\n",
    "                        filename, text = parts\n",
    "                        self.samples.append({'filename': filename, 'text': text})\n",
    "        \n",
    "        print(f\"Loaded {len(self.samples)} samples from {label_file}\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.samples[idx]\n",
    "        \n",
    "        # Load image\n",
    "        image_path = os.path.join(self.image_dir, sample['filename'])\n",
    "        try:\n",
    "            image = Image.open(image_path).convert('RGB')\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {image_path}: {e}\")\n",
    "            # Return a blank image if loading fails\n",
    "            image = Image.new('RGB', (384, 64), color='white')\n",
    "        \n",
    "        # Process image\n",
    "        pixel_values = self.processor(image, return_tensors=\"pt\").pixel_values\n",
    "        \n",
    "        # Process text\n",
    "        labels = self.processor.tokenizer(\n",
    "            sample['text'],\n",
    "            padding=\"max_length\",\n",
    "            max_length=self.max_target_length,\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\"\n",
    "        ).input_ids\n",
    "        \n",
    "        # Replace padding token id's with -100 so they are ignored by the loss\n",
    "        labels[labels == self.processor.tokenizer.pad_token_id] = -100\n",
    "        \n",
    "        return {\n",
    "            'pixel_values': pixel_values.squeeze(),\n",
    "            'labels': labels.squeeze()\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ec0f19",
   "metadata": {},
   "source": [
    "### 4: Setup Model and Processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b081aa31",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Loading TrOCR Model and Processor\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Load processor and model\n",
    "processor = TrOCRProcessor.from_pretrained(\"microsoft/trocr-base-printed\")\n",
    "model = VisionEncoderDecoderModel.from_pretrained(\"microsoft/trocr-base-printed\")\n",
    "\n",
    "# Move model to device\n",
    "model.to(device)\n",
    "\n",
    "# Set special tokens\n",
    "model.config.decoder_start_token_id = processor.tokenizer.cls_token_id\n",
    "model.config.pad_token_id = processor.tokenizer.pad_token_id\n",
    "model.config.vocab_size = model.config.decoder.vocab_size\n",
    "\n",
    "# Set beam search parameters\n",
    "model.config.eos_token_id = processor.tokenizer.sep_token_id\n",
    "model.config.max_length = 128\n",
    "model.config.early_stopping = True\n",
    "model.config.no_repeat_ngram_size = 3\n",
    "model.config.length_penalty = 2.0\n",
    "model.config.num_beams = 4\n",
    "\n",
    "print(f\"✓ Model loaded successfully\")\n",
    "print(f\"✓ Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0092b28",
   "metadata": {},
   "source": [
    "### 5: Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4796a29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Loading Datasets\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Define paths (adjust these to your data location)\n",
    "data_folder = \"data_v1\"\n",
    "train_label_file = os.path.join(data_folder, \"train.txt\")\n",
    "valid_label_file = os.path.join(data_folder, \"valid.txt\")\n",
    "test_label_file = os.path.join(data_folder, \"test.txt\")\n",
    "\n",
    "train_image_dir = os.path.join(data_folder, \"train\")\n",
    "valid_image_dir = os.path.join(data_folder, \"valid\")\n",
    "test_image_dir = os.path.join(data_folder, \"test\")\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = KhmerTextRecognitionDataset(\n",
    "    train_label_file, \n",
    "    train_image_dir, \n",
    "    processor\n",
    ")\n",
    "\n",
    "valid_dataset = KhmerTextRecognitionDataset(\n",
    "    valid_label_file, \n",
    "    valid_image_dir, \n",
    "    processor\n",
    ")\n",
    "\n",
    "test_dataset = KhmerTextRecognitionDataset(\n",
    "    test_label_file, \n",
    "    test_image_dir, \n",
    "    processor\n",
    ")\n",
    "\n",
    "print(f\"✓ Train dataset: {len(train_dataset)} samples\")\n",
    "print(f\"✓ Valid dataset: {len(valid_dataset)} samples\")\n",
    "print(f\"✓ Test dataset: {len(test_dataset)} samples\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79cbd6bc",
   "metadata": {},
   "source": [
    "### 6: Compute Metrics Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa8fbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    \"\"\"Compute CER (Character Error Rate) metric\"\"\"\n",
    "    labels_ids = pred.label_ids\n",
    "    pred_ids = pred.predictions\n",
    "    \n",
    "    # Decode predictions and labels\n",
    "    pred_str = processor.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    labels_ids[labels_ids == -100] = processor.tokenizer.pad_token_id\n",
    "    label_str = processor.batch_decode(labels_ids, skip_special_tokens=True)\n",
    "    \n",
    "    # Compute CER\n",
    "    cer = 0\n",
    "    for pred, label in zip(pred_str, label_str):\n",
    "        # Simple character error rate calculation\n",
    "        pred = pred.replace(\" \", \"\")\n",
    "        label = label.replace(\" \", \"\")\n",
    "        \n",
    "        if len(label) == 0:\n",
    "            if len(pred) == 0:\n",
    "                cer += 0\n",
    "            else:\n",
    "                cer += 1\n",
    "        else:\n",
    "            # Compute Levenshtein distance\n",
    "            distance = levenshtein_distance(pred, label)\n",
    "            cer += distance / len(label)\n",
    "    \n",
    "    return {\"cer\": cer / len(pred_str)}\n",
    "\n",
    "def levenshtein_distance(s1, s2):\n",
    "    \"\"\"Calculate Levenshtein distance between two strings\"\"\"\n",
    "    if len(s1) < len(s2):\n",
    "        return levenshtein_distance(s2, s1)\n",
    "    \n",
    "    if len(s2) == 0:\n",
    "        return len(s1)\n",
    "    \n",
    "    previous_row = range(len(s2) + 1)\n",
    "    for i, c1 in enumerate(s1):\n",
    "        current_row = [i + 1]\n",
    "        for j, c2 in enumerate(s2):\n",
    "            insertions = previous_row[j + 1] + 1\n",
    "            deletions = current_row[j] + 1\n",
    "            substitutions = previous_row[j] + (c1 != c2)\n",
    "            current_row.append(min(insertions, deletions, substitutions))\n",
    "        previous_row = current_row\n",
    "    \n",
    "    return previous_row[-1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7776690",
   "metadata": {},
   "source": [
    "### 7: Custom Trainer with Checkpoint Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb163b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSeq2SeqTrainer(Seq2SeqTrainer):\n",
    "    \"\"\"Custom trainer that saves models at specific epochs\"\"\"\n",
    "    \n",
    "    def __init__(self, *args, checkpoint_epochs=[10, 20, 30, 40, 50], **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.checkpoint_epochs = checkpoint_epochs\n",
    "        self.current_epoch = 0\n",
    "    \n",
    "    def _save_checkpoint(self, model, trial, metrics=None):\n",
    "        \"\"\"Override to save at specific epochs\"\"\"\n",
    "        super()._save_checkpoint(model, trial, metrics)\n",
    "        \n",
    "        # Check if we should save a named checkpoint\n",
    "        if self.current_epoch in self.checkpoint_epochs:\n",
    "            checkpoint_name = f\"khmer-text-recognition-{self.current_epoch // 10}\"\n",
    "            output_dir = os.path.join(self.args.output_dir, checkpoint_name)\n",
    "            \n",
    "            print(f\"\\n{'='*60}\")\n",
    "            print(f\"Saving checkpoint at epoch {self.current_epoch}: {checkpoint_name}\")\n",
    "            print(f\"{'='*60}\")\n",
    "            \n",
    "            self.model.save_pretrained(output_dir)\n",
    "            self.tokenizer.save_pretrained(output_dir)\n",
    "            \n",
    "            print(f\"✓ Saved model to {output_dir}\")\n",
    "    \n",
    "    def training_step(self, model, inputs):\n",
    "        \"\"\"Override to track epochs\"\"\"\n",
    "        return super().training_step(model, inputs)\n",
    "    \n",
    "    def on_epoch_end(self, args, state, control, **kwargs):\n",
    "        \"\"\"Track epoch completion\"\"\"\n",
    "        self.current_epoch = int(state.epoch)\n",
    "        return super().on_epoch_end(args, state, control, **kwargs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1661a365",
   "metadata": {},
   "source": [
    "### 8: Training Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17ea664",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Setting Up Training Configuration\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./khmer-trocr-checkpoints\",\n",
    "    \n",
    "    # Training parameters\n",
    "    num_train_epochs=50,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    \n",
    "    # Optimization\n",
    "    learning_rate=5e-5,\n",
    "    weight_decay=0.01,\n",
    "    warmup_steps=500,\n",
    "    \n",
    "    # Evaluation\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=5,\n",
    "    \n",
    "    # Logging\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=100,\n",
    "    logging_strategy=\"steps\",\n",
    "    \n",
    "    # Generation\n",
    "    predict_with_generate=True,\n",
    "    generation_max_length=128,\n",
    "    generation_num_beams=4,\n",
    "    \n",
    "    # Performance\n",
    "    fp16=torch.cuda.is_available(),\n",
    "    dataloader_num_workers=2,\n",
    "    \n",
    "    # Other\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"cer\",\n",
    "    greater_is_better=False,\n",
    "    push_to_hub=False,\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "print(\"✓ Training arguments configured\")\n",
    "print(f\"  • Epochs: {training_args.num_train_epochs}\")\n",
    "print(f\"  • Batch size: {training_args.per_device_train_batch_size}\")\n",
    "print(f\"  • Learning rate: {training_args.learning_rate}\")\n",
    "print(f\"  • FP16: {training_args.fp16}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1efa1144",
   "metadata": {},
   "source": [
    "### 9: Initialize Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a66e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Initializing Trainer\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "trainer = CustomSeq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=valid_dataset,\n",
    "    tokenizer=processor.tokenizer,\n",
    "    data_collator=default_data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    checkpoint_epochs=[10, 20, 30, 40, 50]\n",
    ")\n",
    "\n",
    "print(\"✓ Trainer initialized successfully\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cddb9d19",
   "metadata": {},
   "source": [
    "### 10: Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301c6c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STARTING TRAINING\")\n",
    "print(\"=\"*60)\n",
    "print(\"This will take several hours depending on your dataset size and GPU\")\n",
    "print(\"Checkpoints will be saved at epochs: 10, 20, 30, 40, 50\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING COMPLETED!\")\n",
    "print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7f7e48",
   "metadata": {},
   "source": [
    "### 11: Save Final Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9540d613",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Saving Final Best Model\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "best_model_dir = \"./khmer-text-recognition-best\"\n",
    "model.save_pretrained(best_model_dir)\n",
    "processor.save_pretrained(best_model_dir)\n",
    "\n",
    "print(f\"✓ Best model saved to {best_model_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db587a3f",
   "metadata": {},
   "source": [
    "### 12: Evaluate on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697eaa5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Evaluating on Test Set\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "test_results = trainer.evaluate(test_dataset)\n",
    "\n",
    "print(\"\\nTest Results:\")\n",
    "for key, value in test_results.items():\n",
    "    print(f\"  • {key}: {value:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3effc55f",
   "metadata": {},
   "source": [
    "### 13: Test Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8fba15",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Sample Predictions\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Test on a few samples\n",
    "model.eval()\n",
    "num_samples = 5\n",
    "\n",
    "for idx in range(min(num_samples, len(test_dataset))):\n",
    "    sample = test_dataset[idx]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pixel_values = sample['pixel_values'].unsqueeze(0).to(device)\n",
    "        generated_ids = model.generate(pixel_values)\n",
    "        generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "        \n",
    "        # Get ground truth\n",
    "        labels = sample['labels'].cpu().numpy()\n",
    "        labels[labels == -100] = processor.tokenizer.pad_token_id\n",
    "        ground_truth = processor.tokenizer.decode(labels, skip_special_tokens=True)\n",
    "        \n",
    "        print(f\"\\nSample {idx + 1}:\")\n",
    "        print(f\"  Ground Truth: {ground_truth}\")\n",
    "        print(f\"  Prediction:   {generated_text}\")\n",
    "        print(f\"  Match: {'✓' if generated_text == ground_truth else '✗'}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a72084",
   "metadata": {},
   "source": [
    "#### 13.5: Generate Training Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a579ce99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Generating Training Graphs\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Read training logs\n",
    "log_history = trainer.state.log_history\n",
    "\n",
    "# Extract metrics\n",
    "train_loss = []\n",
    "eval_loss = []\n",
    "eval_cer = []\n",
    "epochs = []\n",
    "\n",
    "for log in log_history:\n",
    "    if 'loss' in log and 'epoch' in log:\n",
    "        train_loss.append(log['loss'])\n",
    "    if 'eval_loss' in log and 'epoch' in log:\n",
    "        eval_loss.append(log['eval_loss'])\n",
    "        eval_cer.append(log.get('eval_cer', 0))\n",
    "        epochs.append(log['epoch'])\n",
    "\n",
    "# Create figure with subplots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "fig.suptitle('Khmer Text Recognition Training Metrics', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Plot 1: Training Loss\n",
    "if train_loss:\n",
    "    axes[0, 0].plot(train_loss, color='#2E86AB', linewidth=2)\n",
    "    axes[0, 0].set_title('Training Loss', fontsize=12, fontweight='bold')\n",
    "    axes[0, 0].set_xlabel('Steps')\n",
    "    axes[0, 0].set_ylabel('Loss')\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    axes[0, 0].set_facecolor('#F8F9FA')\n",
    "\n",
    "# Plot 2: Validation Loss\n",
    "if eval_loss and epochs:\n",
    "    axes[0, 1].plot(epochs, eval_loss, color='#A23B72', linewidth=2, marker='o')\n",
    "    axes[0, 1].set_title('Validation Loss', fontsize=12, fontweight='bold')\n",
    "    axes[0, 1].set_xlabel('Epoch')\n",
    "    axes[0, 1].set_ylabel('Loss')\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    axes[0, 1].set_facecolor('#F8F9FA')\n",
    "\n",
    "# Plot 3: Character Error Rate (CER)\n",
    "if eval_cer and epochs:\n",
    "    axes[1, 0].plot(epochs, eval_cer, color='#F18F01', linewidth=2, marker='s')\n",
    "    axes[1, 0].set_title('Character Error Rate (CER)', fontsize=12, fontweight='bold')\n",
    "    axes[1, 0].set_xlabel('Epoch')\n",
    "    axes[1, 0].set_ylabel('CER')\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    axes[1, 0].set_facecolor('#F8F9FA')\n",
    "    \n",
    "    # Add best CER annotation\n",
    "    if eval_cer:\n",
    "        best_cer = min(eval_cer)\n",
    "        best_epoch = epochs[eval_cer.index(best_cer)]\n",
    "        axes[1, 0].axhline(y=best_cer, color='green', linestyle='--', alpha=0.5)\n",
    "        axes[1, 0].text(0.02, 0.98, f'Best CER: {best_cer:.4f}\\nEpoch: {best_epoch:.0f}', \n",
    "                       transform=axes[1, 0].transAxes, \n",
    "                       verticalalignment='top',\n",
    "                       bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "\n",
    "# Plot 4: Accuracy (1 - CER)\n",
    "if eval_cer and epochs:\n",
    "    accuracy = [1 - cer for cer in eval_cer]\n",
    "    axes[1, 1].plot(epochs, accuracy, color='#06A77D', linewidth=2, marker='D')\n",
    "    axes[1, 1].set_title('Recognition Accuracy (1 - CER)', fontsize=12, fontweight='bold')\n",
    "    axes[1, 1].set_xlabel('Epoch')\n",
    "    axes[1, 1].set_ylabel('Accuracy')\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    axes[1, 1].set_facecolor('#F8F9FA')\n",
    "    axes[1, 1].set_ylim([0, 1])\n",
    "    \n",
    "    # Add best accuracy annotation\n",
    "    if accuracy:\n",
    "        best_acc = max(accuracy)\n",
    "        best_epoch_acc = epochs[accuracy.index(best_acc)]\n",
    "        axes[1, 1].axhline(y=best_acc, color='green', linestyle='--', alpha=0.5)\n",
    "        axes[1, 1].text(0.02, 0.02, f'Best Accuracy: {best_acc:.4f}\\nEpoch: {best_epoch_acc:.0f}', \n",
    "                       transform=axes[1, 1].transAxes,\n",
    "                       bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.5))\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot\n",
    "plot_filename = 'training_metrics.png'\n",
    "plt.savefig(plot_filename, dpi=300, bbox_inches='tight')\n",
    "print(f\"✓ Saved training graphs to {plot_filename}\")\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n",
    "\n",
    "# Save metrics to JSON for later reference\n",
    "metrics_data = {\n",
    "    'epochs': epochs,\n",
    "    'train_loss': train_loss,\n",
    "    'eval_loss': eval_loss,\n",
    "    'eval_cer': eval_cer,\n",
    "    'accuracy': [1 - cer for cer in eval_cer] if eval_cer else []\n",
    "}\n",
    "\n",
    "with open('training_metrics.json', 'w') as f:\n",
    "    json.dump(metrics_data, f, indent=2)\n",
    "print(f\"✓ Saved metrics data to training_metrics.json\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8dbd1f5",
   "metadata": {},
   "source": [
    "### 14: Save Training Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94d7b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Training Summary\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "summary = {\n",
    "    'total_epochs': 50,\n",
    "    'train_samples': len(train_dataset),\n",
    "    'valid_samples': len(valid_dataset),\n",
    "    'test_samples': len(test_dataset),\n",
    "    'final_test_cer': test_results.get('eval_cer', 'N/A'),\n",
    "    'model_name': 'microsoft/trocr-base-printed',\n",
    "    'best_model_location': best_model_dir\n",
    "}\n",
    "\n",
    "print(\"\\nFinal Summary:\")\n",
    "for key, value in summary.items():\n",
    "    print(f\"  • {key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0516505f",
   "metadata": {},
   "source": [
    "### 15: Zip and Automatically Download All Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a909fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from google.colab import files\n",
    "import time\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Automatic Model Download\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# List of all models to zip and download\n",
    "models_to_download = [\n",
    "    (\"./khmer-trocr-checkpoints/khmer-text-recognition-1\", \"khmer-text-recognition-1\"),\n",
    "    (\"./khmer-trocr-checkpoints/khmer-text-recognition-2\", \"khmer-text-recognition-2\"),\n",
    "    (\"./khmer-trocr-checkpoints/khmer-text-recognition-3\", \"khmer-text-recognition-3\"),\n",
    "    (\"./khmer-trocr-checkpoints/khmer-text-recognition-4\", \"khmer-text-recognition-4\"),\n",
    "    (\"./khmer-trocr-checkpoints/khmer-text-recognition-5\", \"khmer-text-recognition-5\"),\n",
    "    (best_model_dir, \"khmer-text-recognition-best\")\n",
    "]\n",
    "\n",
    "print(\"\\nStarting automatic download process...\")\n",
    "print(\"Zipping and downloading all models...\")\n",
    "print(\"This may take several minutes depending on model size.\\n\")\n",
    "\n",
    "successful_downloads = []\n",
    "failed_downloads = []\n",
    "\n",
    "for idx, (model_path, zip_name) in enumerate(models_to_download, 1):\n",
    "    print(f\"[{idx}/{len(models_to_download)}] Processing {zip_name}...\")\n",
    "    \n",
    "    if os.path.exists(model_path):\n",
    "        try:\n",
    "            # Create zip file\n",
    "            zip_filename = f\"{zip_name}\"\n",
    "            print(f\"  Creating {zip_filename}.zip...\")\n",
    "            shutil.make_archive(zip_filename, 'zip', model_path)\n",
    "            \n",
    "            # Get file size\n",
    "            file_size = os.path.getsize(f\"{zip_filename}.zip\") / (1024*1024)\n",
    "            print(f\"  Size: {file_size:.2f} MB\")\n",
    "            \n",
    "            # Download the file automatically\n",
    "            print(f\"  Downloading {zip_filename}.zip...\")\n",
    "            files.download(f\"{zip_filename}.zip\")\n",
    "            \n",
    "            successful_downloads.append(zip_name)\n",
    "            print(f\"  {zip_name} downloaded successfully!\\n\")\n",
    "            \n",
    "            # Small delay between downloads to prevent issues\n",
    "            time.sleep(2)\n",
    "            \n",
    "        except Exception as e:\n",
    "            failed_downloads.append((zip_name, str(e)))\n",
    "            print(f\"  Error downloading {zip_name}: {e}\\n\")\n",
    "    else:\n",
    "        failed_downloads.append((zip_name, \"Path not found\"))\n",
    "        print(f\"  Warning: {model_path} not found, skipping...\\n\")\n",
    "\n",
    "# Summary\n",
    "print(\"=\"*60)\n",
    "print(\"DOWNLOAD SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nSuccessfully downloaded: {len(successful_downloads)}/{len(models_to_download)} models\")\n",
    "for model in successful_downloads:\n",
    "    print(f\"   • {model}.zip\")\n",
    "\n",
    "if failed_downloads:\n",
    "    print(f\"\\nFailed downloads: {len(failed_downloads)}\")\n",
    "    for model, error in failed_downloads:\n",
    "        print(f\"   • {model}: {error}\")\n",
    "else:\n",
    "    print(\"\\nAll models downloaded successfully!\")\n",
    "print(\"\\nCheck your browser's Downloads folder for the zip files.\")\n",
    "print(\"=\"*60)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
